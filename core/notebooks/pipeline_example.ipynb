{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Załadowanie pełnej ścieżki do projektu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if sys.platform == \"win32\":\n",
    "    # w tym miejscu należy wstawić ścieżkę do projektu na lokalnym dysku\n",
    "    sys.path.append(\"D:/DevSpace/Projects/Research/SeizureDetection\")\n",
    "elif sys.platform == \"linux\":\n",
    "    sys.path.append(\"/mnt/d/gniazdko/SeizureDetection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import potrzebnych bibliotek i modułów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DevSpace\\Projects\\Research\\research_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "\n",
    "from core.utils import ProjectManager, ConfigManager\n",
    "from core.utils import load_model_input_data\n",
    "\n",
    "from core.machine_learning import (\n",
    "    split_data_by_proportions,\n",
    "    create_dataloaders,\n",
    "    evaluate_model_performance,\n",
    "    print_classification_report,\n",
    "    train_and_validate_model\n",
    ")\n",
    "\n",
    "from core.machine_learning.model_builder import R2Plus1DConvNet\n",
    "from core.machine_learning.accuracy import BinaryAccuracy\n",
    "\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicjalizacja ProjectManagera i ConfigManagera do obsługi ścieżek i koniguracji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_manager = ProjectManager()\n",
    "\n",
    "configs_directory_path = project_manager.get_configs_directory_path()\n",
    "primary_data_path = project_manager.get_primary_data_path()\n",
    "model_directory_path = project_manager.get_model_data_path()\n",
    "\n",
    "config_manager = ConfigManager(configs_directory_path)\n",
    "\n",
    "parameters = config_manager.load_config(\"parameters_machine_learning\")\n",
    "data_parameters = parameters[\"data_parameters\"]\n",
    "model_parameters = parameters[\"model_parameters\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Załadowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = load_model_input_data(primary_data_path, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splits = split_data_by_proportions(input_data, data_parameters)\n",
    "\n",
    "# tworzenie dataloderów jest mocno zależne od projektu i problemu\n",
    "# polcam zapoznać się z funkcją create_dataloders i klasą CustomDataset\n",
    "train_data, valid_data, test_data = create_dataloaders(data_splits, data_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tworzenie instancji modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = R2Plus1DConvNet(\n",
    "    in_channels=1,\n",
    "    num_classes=2,\n",
    "    dropout=0.25\n",
    ")\n",
    "\n",
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 16, 18, 64, 64]      --\n",
      "|    └─Conv2Plus1D: 2-1                  [-1, 16, 18, 64, 64]      --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 24, 64, 64]          1,200\n",
      "|    |    └─Conv1d: 3-2                  [-1, 16, 18]              1,168\n",
      "|    └─BatchNorm3d: 2-2                  [-1, 16, 18, 64, 64]      32\n",
      "|    └─ReLU: 2-3                         [-1, 16, 18, 64, 64]      --\n",
      "├─ResidualBlock: 1-2                     [-1, 16, 9, 32, 32]       --\n",
      "|    └─ConvolutionalBlock: 2-4           [-1, 16, 9, 32, 32]       --\n",
      "|    |    └─Sequential: 3-3              [-1, 16, 9, 32, 32]       13,992\n",
      "|    |    └─Conv2Plus1D: 3-4             [-1, 16, 9, 32, 32]       280\n",
      "|    |    └─ReLU: 3-5                    [-1, 16, 9, 32, 32]       --\n",
      "|    └─IdentityBlock: 2-5                [-1, 16, 9, 32, 32]       --\n",
      "|    |    └─Sequential: 3-6              [-1, 16, 9, 32, 32]       13,992\n",
      "|    |    └─ReLU: 3-7                    [-1, 16, 9, 32, 32]       --\n",
      "├─ResidualBlock: 1-3                     [-1, 32, 5, 16, 16]       --\n",
      "|    └─ConvolutionalBlock: 2-6           [-1, 32, 5, 16, 16]       --\n",
      "|    |    └─Sequential: 3-8              [-1, 32, 5, 16, 16]       41,649\n",
      "|    |    └─Conv2Plus1D: 3-9             [-1, 32, 5, 16, 16]       522\n",
      "|    |    └─ReLU: 3-10                   [-1, 32, 5, 16, 16]       --\n",
      "|    └─IdentityBlock: 2-7                [-1, 32, 5, 16, 16]       --\n",
      "|    |    └─Sequential: 3-11             [-1, 32, 5, 16, 16]       55,632\n",
      "|    |    └─ReLU: 3-12                   [-1, 32, 5, 16, 16]       --\n",
      "├─ResidualBlock: 1-4                     [-1, 64, 3, 8, 8]         --\n",
      "|    └─ConvolutionalBlock: 2-8           [-1, 64, 3, 8, 8]         --\n",
      "|    |    └─Sequential: 3-13             [-1, 64, 3, 8, 8]         166,435\n",
      "|    |    └─Conv2Plus1D: 3-14            [-1, 64, 3, 8, 8]         2,101\n",
      "|    |    └─ReLU: 3-15                   [-1, 64, 3, 8, 8]         --\n",
      "|    └─IdentityBlock: 2-9                [-1, 64, 3, 8, 8]         --\n",
      "|    |    └─Sequential: 3-16             [-1, 64, 3, 8, 8]         221,856\n",
      "|    |    └─ReLU: 3-17                   [-1, 64, 3, 8, 8]         --\n",
      "├─AdaptiveAvgPool3d: 1-5                 [-1, 64, 1, 1, 1]         --\n",
      "├─Sequential: 1-6                        [-1, 2]                   --\n",
      "|    └─Linear: 2-10                      [-1, 10]                  650\n",
      "|    └─ReLU: 2-11                        [-1, 10]                  --\n",
      "|    └─Dropout: 2-12                     [-1, 10]                  --\n",
      "|    └─Linear: 2-13                      [-1, 2]                   22\n",
      "==========================================================================================\n",
      "Total params: 519,531\n",
      "Trainable params: 519,531\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 7.12\n",
      "==========================================================================================\n",
      "Input size (MB): 1.12\n",
      "Forward/backward pass size (MB): 15.97\n",
      "Params size (MB): 1.98\n",
      "Estimated Total Size (MB): 19.08\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_data=(1, 18, 128, 128));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicjalizowanie niezbędnych obiektów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = CrossEntropyLoss()\n",
    "accuracy_fn = BinaryAccuracy()\n",
    "\n",
    "optimizer = SGD(\n",
    "    params=model.parameters(),\n",
    "    lr=model_parameters[\"learning_rate\"],\n",
    "    weight_decay=model_parameters[\"weight_decay\"])\n",
    "    \n",
    "lr_scheduler = StepLR(\n",
    "    optimizer,\n",
    "    step_size=model_parameters[\"step_size\"],\n",
    "    gamma=model_parameters[\"gamma\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has started...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:09<01:29,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n",
      "Training loss: 0.7899 | Validation loss: 0.7436\n",
      "Training accuracy: 0.4983 | Validation accuracy: 0.4703\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:20<01:20, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2\n",
      "Training loss: 0.7735 | Validation loss: 0.7434\n",
      "Training accuracy: 0.4992 | Validation accuracy: 0.4703\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:29<01:08,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3\n",
      "Training loss: 0.7720 | Validation loss: 0.7426\n",
      "Training accuracy: 0.4988 | Validation accuracy: 0.4703\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:39<00:58,  9.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4\n",
      "Training loss: 0.7633 | Validation loss: 0.7418\n",
      "Training accuracy: 0.4985 | Validation accuracy: 0.4703\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:48<00:48,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5\n",
      "Training loss: 0.7597 | Validation loss: 0.7401\n",
      "Training accuracy: 0.4988 | Validation accuracy: 0.4703\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:58<00:38,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 6\n",
      "Training loss: 0.7532 | Validation loss: 0.7388\n",
      "Training accuracy: 0.4992 | Validation accuracy: 0.4703\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [01:08<00:29,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7\n",
      "Training loss: 0.7489 | Validation loss: 0.7376\n",
      "Training accuracy: 0.4990 | Validation accuracy: 0.4703\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [01:18<00:19,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8\n",
      "Training loss: 0.7424 | Validation loss: 0.7365\n",
      "Training accuracy: 0.4986 | Validation accuracy: 0.4703\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [01:27<00:09,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 9\n",
      "Training loss: 0.7393 | Validation loss: 0.7347\n",
      "Training accuracy: 0.4987 | Validation accuracy: 0.4703\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:38<00:00,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 10\n",
      "Training loss: 0.7374 | Validation loss: 0.7334\n",
      "Training accuracy: 0.4988 | Validation accuracy: 0.4703\n",
      "\n",
      "Training of 'seizure detection model' completed after 10 epochs.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# polecam zapoznać się z train_and_validate_model oraz z funkcją perform_step -> plik engine.py\n",
    "results = train_and_validate_model(\n",
    "    model=model,\n",
    "    train_dataloader=train_data,\n",
    "    valid_dataloader=valid_data,\n",
    "    loss_fn=loss_fn,\n",
    "    accuracy_fn=accuracy_fn,\n",
    "    optimizer=optimizer,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ocena modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- -- Model Evaluation: -- --\n",
      "Loss: 0.7090\n",
      "Accuracy: 0.5228\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  0 293]\n",
      " [  0 321]]\n",
      "\n",
      "Precision Score: 0.5228\n",
      "Recall Score: 1.0000\n",
      "F1 Score: 0.6866\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = evaluate_model_performance(model, test_data)\n",
    "print_classification_report(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zapisanie wag modelu\n",
    "# torch.save(model.state_dict(), ścieżka_do_katalogu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Załadowanie wag modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\n",
    "    os.path.join(\n",
    "        os.path.join(\n",
    "            model_directory_path,\n",
    "            \"classifier_2025-03-14_19-03\"\n",
    "        ),\n",
    "        \"model.pth\"\n",
    "    )\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- -- Model Evaluation: -- --\n",
      "Loss: 0.2672\n",
      "Accuracy: 0.9072\n",
      "\n",
      "Confusion Matrix:\n",
      " [[272  21]\n",
      " [ 36 285]]\n",
      "\n",
      "Precision Score: 0.9314\n",
      "Recall Score: 0.8879\n",
      "F1 Score: 0.9091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = evaluate_model_performance(model, test_data)\n",
    "print_classification_report(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
